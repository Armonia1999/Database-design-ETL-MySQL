{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wanhui Citizens Database Design\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We have been contacted by Chen Cheng, The Supreme Ruler of Wanhui Society, to solve his problem. According to him, a lot of martial artists started abandoning their sects and disappear. Coincidentally, random acts of violence started to occur in different parts of the country and he suspects that the rouge martial artists are behind it. Furthermore, some sects started to get too strong and he suspects they might be trying to overthrow him by joining forces. That's why he wants us to design a database and populate it with all of the citizens info so he can track their movements. A bit suspicious, but we agree nonetheless because the pay is way too good to turn down.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After asking him more questions to be able to get a grasp of what we are dealing with , we learn this information:\n",
    "* Wanhui is basically built upon a group of sects who have a number of people belonging to it, who all train and live on it's lands. \n",
    "* There are some alliances between some sects, reason for that is to expand their knowledge and business. Not being in an alliance with another sect doesn't necessarily mean they are foes, after all, they all follow the supreme ruler. \n",
    "* People can cultivate different things, for example they cultivate the power of shadows, or the nature. This should be included in the database.\n",
    "* There are 9 levels to rank the citizens power: 1-3 is for the beginner practitioners, 4-6 for the intermediate ones and lastly 7-9 for the the advanced. \n",
    "* We are only interested in the people aged 15-77 since the other are not much of a threat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As an initial design , we need 4 tables in our database :\n",
    "* Citizens table to hold info on the citizens themselves.\n",
    "* Sects table to keep info on the sects themselves. \n",
    "* Alliance table to see which sects get along together. \n",
    "* Inventory table to keep track of what weapons does each sect has. \n",
    "\n",
    "##### Obviosuly the database will be tampered with as we keep going but for now this is what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 1: Extract our data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For this step we will use Selenium to scrape some of the data we need while using Faker's library to generate the other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first off let's type the small data ourselves. Like alliances names and cultivation powers.\n",
    "\n",
    "cultivation_list = [\"Demonic\", \"Shadow\", \"Light\", \"Poison\", \"Plants\", \"Darkness\", \"Wind\", \"Lightning\", \"Water\", \"Earth\", \"Physical Strength\"\n",
    "                    ,\"Wisdom\", \"Souls\", \"Magic\", \"Sword\", \"Medicine\", \"Array\", \"forest\", \"Fire\", \"telekinesis\", \"Minds\"]\n",
    "\n",
    "alliance_list = [\"Iron Brotherhood Alliance\", \"Beast Tamers Alliance\", \"Holy Lands of Flame Allinace\",\n",
    "             \"Truth Seeking Alliance\", \"Heaven Trampling Alliance\", \"Godly Phoenix Alliance\", \"Demon Banishment Alliance\"\n",
    "            , \"Death Masters Alliance\", \"Etheral light Alliance\", \"Northern Wall Alliance\", \"Central Heavenly Alliance\", \"Crimson Dragons Alliance\"\n",
    "            , \"Shadow Vengeance Alliance\", \"Silent Night Alliance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries we will use throughtout this mission.\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--profile-directory=Default\")\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument('--no-sandbox') \n",
    "options.add_argument('--disable-dev-shm-usage')        \n",
    "options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "options.add_argument(\"start-maximized\")\n",
    "options.add_argument(\"--incognito\")\n",
    "options.add_argument(\"--disable-site-isolation-trials\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(service = Service(executable_path='C:/Users/armon/Downloads/chromedriver_win32/chromedriver.exe'), options=options)\n",
    "\n",
    "from faker import Faker \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv \n",
    "import random\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's start scraping. First off let's get the names of sects. \n",
    "\n",
    "def get_sect_names():\n",
    "\n",
    "    driver.get('https://www.fantasynamegenerators.com/wuxia-sect-names.php')\n",
    "    time.sleep(3)\n",
    "    final = []\n",
    "    load_more = driver.find_element(By.XPATH, '//*[@id=\"nameGen\"]/input')\n",
    "  \n",
    "    for _ in range(10):   # each loop gives us 10 names so 100 names is more than enough. We didnt choose a smaller number because sometimes there are duplicates, ew.\n",
    "        time.sleep(2)\n",
    "        result = driver.find_element(By.XPATH , '//*[@id=\"result\"]').get_attribute(\"innerText\").split('\\n')\n",
    "        for sect in result:\n",
    "            if len(sect) > 0:\n",
    "                sect_name = sect.split(' ')[0]\n",
    "                final.append(sect_name)\n",
    "    \n",
    "        driver.execute_script(\"arguments[0].click();\", load_more)\n",
    "    driver.close()\n",
    "    return final\n",
    "\n",
    "\n",
    "sects_list = get_sect_names()\n",
    "sects_list = list(dict.fromkeys(sects_list)) ## to get rid of duplicates\n",
    "\n",
    "sects_backup = pd.DataFrame(sects_list)\n",
    "sects_backup.to_csv('sects_backup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got sects outta the way, now for the names. \n",
    "\n",
    "global backup\n",
    "backup = []\n",
    "\n",
    "\n",
    "def get_citizen_names():\n",
    "\n",
    "    final = []\n",
    "    driver = webdriver.Chrome(service = Service(executable_path='C:/Users/armon/Downloads/chromedriver_win32/chromedriver.exe'), options=options)\n",
    "    driver.get('https://blog.reedsy.com/character-name-generator/language/mandarin-chinese/')\n",
    "    time.sleep(3)\n",
    "    load_more = driver.find_element(By.XPATH, '//*[@value=\"Generate names\"]')\n",
    "\n",
    "    for _ in range(10000):\n",
    "        time.sleep(2)\n",
    "        result = driver.find_elements(By.XPATH, '//*[@id=\"names-container\"]')\n",
    "        for item in result:\n",
    "            names = item.find_elements(By.TAG_NAME, \"h3\")\n",
    "            time.sleep(2)\n",
    "            for name in names:\n",
    "                global backup\n",
    "                time.sleep(1)\n",
    "                ch_name = name.get_attribute(\"innerText\")\n",
    "                time.sleep(1)\n",
    "                backup.append(ch_name)\n",
    "                final.append(ch_name)\n",
    "                time.sleep(1)\n",
    "        driver.execute_script(\"arguments[0].click();\", load_more)\n",
    "    \n",
    "    return final\n",
    "\n",
    "\n",
    "# We used whatever we could gather in the backup list, because the function takes wayyyyyyyyyy too long. and after running for 7 hrs once, I thought it collected like 30k names but that website has a lot of duplicates and I ended up with like 8k. so yeah, we will use the backup list.\n",
    "\n",
    "names1 = list(dict.fromkeys(backup))\n",
    "names = pd.DataFrame(names1)\n",
    "names.to_csv('names_backup.csv')  # Always build a habit of saving the data you gather if it's large, just in case you need some and you offline or something happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need more names so we will use faker library to extract romanized chinese names (pinyin)\n",
    "\n",
    "fake = Faker(\"zh_CN\")\n",
    "\n",
    "faker_names = []\n",
    "\n",
    "for _ in range(1000000):\n",
    "    faker_names.append(fake.romanized_name())\n",
    "\n",
    "fakes = list(dict.fromkeys(faker_names))\n",
    "\n",
    "fakes1 = pd.DataFrame(fakes)\n",
    "fakes1.to_csv('fakes_backup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something I wanted to do as well, get actual chinese names and not romanized. But I kept pinyin for the people who prefer it and dont know how to read the Chinese characters.\n",
    "\n",
    "chinese = []\n",
    "\n",
    "for _ in range(1000000):\n",
    "    chinese.append(fake.name())\n",
    "\n",
    "chinese_names = list(dict.fromkeys(chinese))\n",
    "chinese = pd.DataFrame(chinese_names)\n",
    "chinese.to_csv('Chinese_names_backup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We got the data we needed and now we need to get it back from the csv files and transform it a bit. You might ask, why extract from the csv files and not from the lists that are already available. The thing is, imagine your laptop turned off or you got disconnected and no wifi and now you have to scrape all over again... not fun huh? especially if it takes hours and hours on end. Plus, it might be fun to learn how to read data from a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2: Transform our data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What we will be doing here is basically join together the names we got through scraping and the names we got from the faker library and make sure there are no duplicates. Before starting, keep in mind that the names we extracted from faker are in the form : given name + surname while the names we got through scraping are in the format surname + given name. So we need to bear that in mind. I like the latter format more, so we will go with that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get our faker names and switch between the surname and given name\n",
    "\n",
    "fake_pinyin = []\n",
    "\n",
    "with open('fakes_backup.csv') as f:\n",
    "    lines = [line.split(',') for line in f]\n",
    "    for line in lines:\n",
    "        full_name = line[1].split('\\n')[0]\n",
    "        split = full_name.split(' ')\n",
    "        fake_pinyin.append(split[1] + \" \" + split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now extract the backup names in a list too.\n",
    "\n",
    "backup_names = []\n",
    "\n",
    "with open('names_backup.csv') as f:\n",
    "    lines = [line.split(',') for line in f]\n",
    "    for line in lines:\n",
    "        full_name = line[1].split('\\n')[0]\n",
    "        backup_names.append(full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join together and make sure no duplicates \n",
    "\n",
    "pinyin_names = fake_pinyin + backup_names\n",
    "complete_pinyin_names = list(dict.fromkeys(pinyin_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also get our chinese names nice and ready. This is not necessary since the function that generates them runs really fast and no need to bother with csv reading. But I did so because I love making my life hard.\n",
    "\n",
    "complete_chinese_names = []\n",
    "\n",
    "with open('Chinese_names_backup.csv') as f:\n",
    "    lines = [line.split(',') for line in f]\n",
    "    for line in lines:\n",
    "        full_name = line[1].split('\\n')[0]\n",
    "        complete_chinese_names.append(full_name)\n",
    "\n",
    "# seems like there is an encoding issue with reading chinese characters from csv files, but will pass since getting them through faker takes less than a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Our data now is finally ready for the last step..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Step 3: Load our data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we will be creating our database and populate it, hurray ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our database. \n",
    "\n",
    "db = mysql.connector.connect(host = \"localhost\", user = \"root\", password = \"##########\")\n",
    "\n",
    "mycursor = db.cursor()\n",
    "\n",
    "mycursor.execute(\"CREATE DATABASE WANHUI\")\n",
    "\n",
    "db = mysql.connector.connect(host = \"localhost\", user = \"root\", password = \"##########\", database = 'WANHUI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with the easiest table: alliances.\n",
    "\n",
    "mycursor.execute(\"CREATE TABLE alliances (ID INT PRIMARY KEY AUTO_INCREMENT, alliance_name VARCHAR(100) NOT NULL) \")\n",
    "\n",
    "vals  = \", \".join(f\"('{alliance}')\" for alliance in alliance_list)\n",
    "mycursor.execute(f\"INSERT INTO alliances (alliance_name) VALUES {vals}\")\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's continue with the sects table:\n",
    "\n",
    "mycursor.execute(\"CREATE TABLE sects (ID INT PRIMARY KEY AUTO_INCREMENT, sect_name VARCHAR(100), alliance_id INT)\")\n",
    "\n",
    "vals = []\n",
    "for sect in sects_list:\n",
    "    vals.append((sect, random.randint(1,14)))\n",
    "\n",
    "sql = \"INSERT INTO sects (sect_name, alliance_id) VALUES (%s, %s)\"\n",
    "\n",
    "mycursor.executemany(sql, vals)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only the Sect master column is missing, but we will add it after we create the citizens. Let's Build the Inventory Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"CREATE TABLE inventory (ID INT PRIMARY KEY AUTO_INCREMENT, sect_id INT, swords INT, arrows INT, poison INT, daggers INT, ships INT, SS_Rated_weapons INT )\")\n",
    "\n",
    "vals = []\n",
    "i = 1\n",
    "\n",
    "for sect in sects_list:\n",
    "    vals.append((i, random.randint(0,5000), random.randint(0,10000), random.randint(0,1000), random.randint(0,1000) , random.randint(0,50) , random.randint(0,10)))\n",
    "    i = i+1\n",
    "\n",
    "sql = \"INSERT INTO inventory (sect_id, swords, arrows, poison, daggers, ships, SS_Rated_weapons) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "mycursor.executemany(sql, vals)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the last table, citizens.\n",
    "\n",
    "sql = \"\"\"CREATE TABLE citizens(\n",
    "    ID INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    full_name VARCHAR(100),\n",
    "    age INT,\n",
    "    Gender ENUM('F', 'M'),\n",
    "    cultivation VARCHAR(100),\n",
    "    power_rank INT,\n",
    "    isRouge ENUM('Yes', 'No'),\n",
    "    sect_id INT)\"\"\"\n",
    "\n",
    "mycursor.execute(sql)\n",
    "\n",
    "vals = []\n",
    "\n",
    "weights = [0.99, 0.01]\n",
    "\n",
    "ranks = ['1','2','3','4','5','6','7','8','9']\n",
    "ranks_weight  = [0.25, 0.15, 0.20, 0.15, 0.10, 0.05, 0.06, 0.03, 0.01 ]\n",
    "\n",
    "for name in complete_pinyin_names:\n",
    "    vals.append((name, random.randint(15, 77), random.choice(['M', 'F']), random.choice(cultivation_list), np.random.choice(ranks, p=ranks_weight), np.random.choice(['No', 'Yes'], p=weights), random.randint(1,30)))\n",
    "\n",
    "sql = \"INSERT INTO citizens (full_name, age, Gender, cultivation, power_rank, isRouge, sect_id) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "mycursor.executemany(sql, vals)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this last step, I will also include an extra citizens table with the chinese names. \n",
    "\n",
    "sql = \"\"\"CREATE TABLE citizens_CH(\n",
    "    ID INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    full_name VARCHAR(100),\n",
    "    age INT,\n",
    "    Gender ENUM('F', 'M'),\n",
    "    cultivation VARCHAR(100),\n",
    "    power_rank INT,\n",
    "    isRouge ENUM('Yes', 'No'),\n",
    "    sect_id INT)\"\"\"\n",
    "\n",
    "mycursor.execute(sql)\n",
    "\n",
    "vals = []\n",
    "\n",
    "weights = [0.99, 0.01]\n",
    "\n",
    "ranks = ['1','2','3','4','5','6','7','8','9']\n",
    "ranks_weight  = [0.25, 0.15, 0.20, 0.15, 0.10, 0.05, 0.06, 0.03, 0.01 ]\n",
    "\n",
    "for name in chinese_names:\n",
    "    vals.append((name, random.randint(15, 77), random.choice(['M', 'F']), random.choice(cultivation_list), np.random.choice(ranks, p=ranks_weight), np.random.choice(['No', 'Yes'], p=weights), random.randint(1,68)))\n",
    "\n",
    "sql = \"INSERT INTO citizens_CH (full_name, age, Gender, cultivation, power_rank, isRouge, sect_id) VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "mycursor.executemany(sql, vals)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And that's it for our ETL process, Next stop is going to MySQL Workbench to explore our data. See you there ~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('armoniaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22d60d744825d23d2a3101c9dcecba3dfeee6586418d1cdc2c97b54096b06772"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
